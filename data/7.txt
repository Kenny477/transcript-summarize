 Wait, wait, wait. Copying. Okay. I'm lead to introduce today coffee silhouette none, which is our former chair and professionally now the parchment. And he is edx, the automated reasoning group. And our department, which is I will for better, well perhaps you will. Which deals with, with all the AI, meaning not deep learning. Day. The, all the, all the AI put deep learning is just we learned how to approximate functions on their own. It's not important. Well, that's a good question. But really the, probably the big advance will be marrying the two. But it's not there yet. Their marriage is not yet successful. So and he's a fellow of the pre-built AI and the ACM and elite former chief of the Journal of artificial intelligence and has a book about Bayesian networks. And to adjust your Herbert, he, he did, is under graduate college and university quenched in Kuwait. And he's a PhD in Stafford. So, you know, especially getting from Kuwait to Stanford means that that professor 89 was already a professor of them. Okay. It's the the floor is yours and not for the next week. Thank you. Thank you. All right, So we'll be talking about AI today. That's very exciting subject as you want. Now it's being really getting a lot of attention recently due to all of the successes and the way it has impacted our lives in some way. So this is a field of computer science, is splitting all the actually people started working on this about 70 years ago. And it's trying to basically understand intelligence and Asians or systems that are intelligent and that behavior. And this includes being able to perceive your environment, understand what's going on, predict the future environment, and learn from that experience. This is all of the things that we tend to attribute to intelligent human beings. And what this has showed over 70 years of research as it's getting hard yet possible to do these things. And it's actually a lot of fun and rewarding. Just some general remarks before we move on is initially the idea was that you would want all of these things and where you would want to call this the monolithic approach. Trying to produce things like mist, data figure and in Star Trek. And what that turns out to be is you really don't, if you can do any of these things, you can actually have a lot of applications and a lot of value to society. And we would see applications of that as we go on. And again, one, initially, maybe the idea was that you had the trauma that's going around, which is hardware embodiment of intelligence. A lot of what's happening today is actually in software to be not hardware at all. And, and just again, before we move on, I want to make an important distinction here. If you're trying to build intelligent agents and deploy them, there is a distinction between are you doing this? Why? So that they will do intelligence in a very general setting versus are you operating in a controlled environment and target degenerate and stuff. It's very hard and we're still pretty far away from that. But when you're operating in a specific context, trying to do something specific as far as the best, significant progress. And in fact, you can beat humans easily in these situations. And again, you can see what that means as we go on. But a couple of other remarks about why AI is particularly exciting and also attracts a lot of attention. And is that it's broad goals is shared by things that are far away from computer science in a sense. So philosophy, cognitive science, neuroscience that all interested in the subject with the distinction that understanding versus being so these fields, we're interested in understanding a human thing, human behavior, human intelligence, AI, computer scientists interested in understanding up to the point of helping us and building. So we do not necessarily insist on mimicking humans. We use humans as an inspiration and human intelligence as an explanation. And when you look at the specific goals, like perception or learning, or understanding and prediction, they intersect with very specific fields. Linguistics, statistics, mathematical logic study the specific aspects. Today, for example, machine learning, the work that's happening in that area. It's hard to distinguish between researchers doing that in computer science, but statistics, for example. They're basically do similar things, publish in some other places and so on. Again, before we move on, just for historical reference, people from day one, they were worried about or trying to define when is it that we would reach human intelligence? And that is famously known as the Turing test. Alan Turing is a very important trigger and computer science and science. His name is attached to the Turing Award, which is like the Nobel Prize and computer science. And he proposed this test in the 50s, which is basically that says if you can fool, if you're interacting with something that is sitting behind a curtain and you're not able to tell whether this is a computer or a human, then we've reached basically pass the test, right? So you interact with something on the other side, you don't know it could be a machine. If it's a machine and you confuse it with the human than, than we got that. That's now people don't take this seriously today. I figured out that this is more of a test of the human gullibility more than anything else. But you need to know about the Turing test and I'm doing in particular and the tuning. Warren. And they wanted to recent attempts to redefine and have other notions. And I'm not going to go over that what I just mentioned. Now, if you open up like a comprehensive book on AI, like the way I hope that we use in our undergraduate course. You will find a picture that looks like this about what are the ingredients of an intelligent agent if we were to do everything. And you will see components for having knowledge. You have to know, for reasoning, for learning, and abilities to interact with your environment. This could be through different modalities, speech, vision and natural language, text and so on. So what are we going to do today is we're just going to peek through some of the subjects will give you a sense of what's going on. And you'll see that actually the things have evolved over the years, decade after decade of AI research. Winds shift in one direction versus the other. And you'll also get a sense of what you would cover if you take an Intro to AI course. And I'm going to start with the knowledge representation and reasoning. We talk about learning and talk about a couple of vitamins and these toolboxes as well. So knowledge representation and reasoning. You can imagine that this was one of the first topics people were when they started doing yeah, almost four decades everything was focused on knowledge representation and reasoning. If you're going to be intelligent, you have to know, thanks, and we have to be able to reason and draw conclusions. And people learn things the hard way. Many of things I'm going to say now look very obvious, but they took people decades to the forget them out. One of these is the fact that school types of knowledge, what we call factual knowledge and beliefs, uncertain knowledge. Now, when I say it sounds very intuitive and obvious, but people work on factual knowledge for at least a couple of decades. Probably allies know who want to build intelligence. We have two leaves unsettling published now I'm going to give you examples of that next. And they grapple with issues like what is relevant knowledge when you're solving a particular set. Squat part to be knowledge is irrelevant to that. Where do you acquire knowledge and so on. So let's take a look at an example of what we'd call factual March. And this is actually a puzzle that some of you may have seen where it's actually was yields the amount of the homework problems and our undergraduate course, nine weeks that course. It talks about four people knew about that then must either be among them. They hold a different jobs and each holds exactly two jobs. Yacht, chef, gardeners, dot, dot, dot. And then eventually asked the question who holds which jumps. Now, this is factual knowledge. Everything I'm saying is in fact, fact facts back. And there are tools for we know how to do these things very well today we can represent this knowledge in a formal way of using logic. There are different types of logic and then we can use automated reasoning to resolve the spasm. You can do this as an undergraduate, but by the things you learn and an undergraduate course, which you want to represent this using polygons, episodic or first-order logic. It would look like this. But basically this is something we know articles ready when today to capture factual knowledge and conclusions. Based on that. Now, as I said, if you can spend a couple of decades just doing this and then they discovered one way. There's a lot of information of them that is not certain factual. Here's another story. Again, this comes actually from a homework problem from our undergraduate course on the subject. And this is about like inseminated, artificially inseminating a cow. And then we want to know whether the procedure succeeded. So you have tests, you have a scanner, that's the neuron. The best of luck this. But if you do the test and it comes out positive, that doesn't necessarily confirm pregnancy, that has a probability of confirming pregnancy. It same thing for the other test and the procedure itself. It's not certain based on historical data that only succeeds in 80% of the time. So everything here is highly unlikely, but not for sure. And then the question is, okay, we did the procedure that we did the tests. One of them came out positive when it came out negative, what can we say about ligaments? All right, so in the eighties, people worked a lot on this and there are different approaches for how do you represent knowledge, how do you manipulate that? And one of the most successful approach is based on what's known as Bayesian networks or belief networks. You see a picture of that here. In fact, this was developed by our own firm, who actually won the Turing Award, which is like the Nobel Prize for work on the subject and related subjects and AI. This screenshot here is actually from system that, that my group developed. People get to use it. They use the number of classes or the other graduate level. It's widely used nationwide actually for representing and dealing with concepts and knowledge. Now, this is as far as representing knowledge. Now when you come to reasoning, thinking situations actually is pretty interest. And here I need to make a distinction between two things. Now when we look at human reasoning, there are a lot of forms of something called deduction. Where do we draw conclusions of what we know, whether it is certain or uncertain? There are things like belief revision, reasoning with contradictions. I have some beliefs. I observe something that contradicts what I know and I want to resolve the contradiction by giving up some of my beliefs of the time. Causality. What causes what. Now the distinctions is that for some of these tasks, like deduction, we have figured out mathematically, we know what it means to deduce new conclusions from existing knowledge. Seven. And the only thing that happens here is how to do this. How do I do it with the fastest possible way in using as the minimum amount of memory. How can I implement these algorithms on simple platform was like your watch or your iPhone or pixel. It's 3D algorithmic. But for some other tasks, like we need a vision, for example, we happen to good people. Even philosophers have been working on this for decades. We still don't know really how people devise therapeutics, how do the EDs amount that compel evictions. So still ongoing work that has been receiving a lot of attention recently, a lot of progress, but not again, not universally accepted. So the abduction you will, you will not find anybody basically agrees on what the much as what you will find disagreements on some of these other topics. You will get the slides. I'm not going to read you the story, but this is a story that is from a book called How to change your mind by a philosopher. He took gardening fours on belief revision, whole book on the subject of belief revision. It's basically about someone who bought that important that why it's supposedly goal but it got stained by. So if I had said it's not supposed to and then he's trying to find out they didn't get Stay. Did he get that? I said acid. Was he cheated. And it's very entertaining, simple story that gives you a sense of what we do almost every day when we see things that contradict with our perceptions or our knowledge. So what is, what is, what is the difference between the peak and and getting more information, which in other words, I don't understand the difference. We've made a belief revision and inseminated cow, then doing what was it? Doing some tests and get a positive. And now we have some opinion and suddenly we do the blood test and it's negative. So now this is why this is not one bit. This is one of the approaches and one of the disagreements that you'll see is whether we need probabilities for that. And can you do belief revision without relevant this? And this is one of these is basically disagreements and the literature. So some philosophers want to be able to say something about this without invoking the notion of probably is. But you're right in the sense that from a practical point of view, a lot of what, how this gets implemented is using policy beliefs, but that's not necessarily be the case. Now, moving on causality, this is something that's been getting a lot of additional exactly. You would get back to that later, but it is viewed actually by some as something that to me would need to do to be able to movie. I took the next step. Again, it's not something that's completely set them. It's a lot of progress over the last years. You need this to be able to explain, to put a big, to know how to control and ensure that certain things happened and attracted a Perl has been dedicating his life recently to causality. If you want to read about this, he actually wrote a book called The Book of y, which is meant for a general audience. It was a bestseller, came out a couple of years ago, sample by neighbors and relatives, actually by bike do with computer science fed this that found it quite informative. Pertaining, so it's recommended reading. Now, if you know how to do knowledge representation and reasoning alone without any of the other things we talked about without natural language, without perception, without burning, you can actually do quite a bit. And here's a list of applications that are enabled by knowledge representation and reasoning. You can look at symptoms of a patient and conclude what is the most like the disease they buy, how you swipe a card. Making a transaction, is that you or someone else who stole your car than that making this transaction formal verification software system is correct. Is it, is it really going to do what you expected To do? The techniques that come from for my vacation, from trauma to knowledge, representation and reasoning, and so on, product configuration. Am I going to tell you about this except to point to an Arctic them that the heart from the you said a few years back about some work that I did and that was adopted to do product configuration for one-on-one the online systems than what I mean by that major companies. So I do have quite a bit more to cover. And I'd like to now move to yet another topic with them, this picture. And the next thing I want to talk about is Natural Language Processing, which is something that has been receiving a lot of attention recently. Again, it's one of the things that worked on from the very early days of AI and then it died off. And now it's basically making waves. It's everywhere, right? So this is where in general you're trying to interact with the computer using text, using natural language. You want to go to a computer and say, Mr. employees that have been working here for more than three years, I have not gotten the base. We want to be able to get back an answer and natural language, there are actually only two employees. These are just names. You want to use this to summarize texts. You take an article and generate 100 word that stack of it. And of course, the biggest application today is a machine translation. When I look at webpages and the language you got to understand and then translate them into a language that you understand. Now in speech transcription, voice assistance everywhere today. And then what's interesting is, as I said, people started doing this. In fact, machine translation is from a very early days of AI and it's considered a fail, but we'll start with a very long time. Now. It's everywhere. So what happened actually, its interests come first. Doing language is hard. And, and people typically talk about the notion of ambiguity because it's really hard to just look at a text and understand it. Eating without knowing a lot of other things. People talk about syntactic ambiguity. They talk about they are cooking, apples is cooking and a verb or an edge that she ran to the bank. What does that mean that she loaded the bank to withdraw money or did she go to the river back? Can you open the door? Is this request or is this a question? And the all method for dealing with these problems, the classical one was that if I want to do this, I really have to know a lot about the war. And I need to then use this knowledge and reasoning to disambiguate. Do these tasks that people work on this for a very long time, it doesn't go part. The underlying technology of what's happening today is very different than it's based on machine learning. We're going to talk about this, but the idea is you're going to use data. Probably the simplest example to explain this is machine translation. So instead of taking sentences and parsing them on understanding the meaning of the Worlds and evolving knowledge. No, I just give me, let's say looking at acoustic from English to French, just the sentences, English sentence to French. English sentence for instance. And give me a lot of these, I'm going to try to detect the patterns and then do machine translation without even really knowing what I'm looking at. And you would be like really this works. And yes, in fact, that's what's happening today. And when you look at the system that you see today that are being used by billions of users every day. That's what they're based on. In fact, pattern matching or this machine learning approach that just ties to look at data and mimic it is surprisingly also works across languages. So the same technology you can use it for translating between any pair of languages. In fact, be systems like Google Glass, they'd been, you can pick any pair of languages and it will actually go ahead and do that. These are things, these things work amazingly well. You look at it and saying, Wow, But then they can really fall apart completely, right? So let, let me give you an example. I wrote an article about the state of AI couple of years ago which got a lot of attention. So it was discussed extensively on Twitter and some of the posts where languages I don't understand, this wasn't a Turkish and then I try to translate. Okay, this is an installation of this and you read it. Where are we in our machine intelligence? How has our perception about that? She just changed over the years? It's a very thought-provoking articles that touches both an academic and social parts. Fantastic, looks, great. The intriguing part is the system that did the statistician doesn't know the meaning of any of these words. Does not mean what is perception? What is actually, what's Academy has no idea. It just was doing basically learn by association effective. So it's just fantastic. Now you, this is the same example. I tried it. I went to one of the responses and I say these two systems out there and allows thinks that looked at a little bit, is one system. I'm not going to name them, but these are two machine fascinating system, the two big ones at Easter, so it can be so discreet and so beautiful. I'll make a note of it many times. And the second translation was, is it possible that such a mistake it would be soil, they're so beautiful. Liquid Express, I'm going to make a few more and I've got an article, I'm going to have a certain budget. Okay, rubbish now. And after realized none of these systems know what's going on, it can get even more dramatic. Let me show you this exactly like start looking at the individual sentences just to see what I mean. This sentence was translated by the same system opened up. Now, the only difference between this and that is this hasn't thought that this did not happen. It was actually an accident. But look what this guy translated into. A researcher can be solved discrete and that's it. So when this was that essentially we saw the sleep and suddenly when done. Right. Now, you shouldn't be surprised when you see these things because I gave this instance, has no idea what was bewildered. Well as the recession was, they have no idea what's going on underneath. But it is remarkable that you can still get so much value. I mean, look, if you're looking at a pace that's in a language you don't understand and you get like 90% of it. It's just fantastic. All right, and without having to do any grammar, any semantic analysis, sending knowledge, you can still get that. And here we get to something interesting, one of the main applications of these, and probably a lot of you have heard about is it's chatbots like when you call verse system online using natural language. First thing you have to note is, even though we're getting a lot of attention from the study, this is a very old idea and the first system, but the discourse from the sixties called eliza was one of the implementations of that system online. I tried that at some point, had the conversation with that. And you can see what's going on there. If you read. These systems are a bit naive. They will take your setup instance and they will just have templates and then just turned them around. Today, people do this in a more sophisticated way. They do it using meshgrid learners. And when you use it in a context like technical support, you can actually get it to work to a very large extent. Maybe an 80 percent, 90 percent of the time, you will have a meaningful conversation, you solve your problem. The other cases you basically try to ask for an operator. One of the advances that happens, which is a major thing, is this notion of what the bed, what happened initially is the old days. If you have the word department, chair or faculty, we would use that word as a symbol. And then when we match the match symbol to symbol, now people to present these words using vector of numbers and the vector that gets used this application specific. So you train your system so that as these fuzzy representations of words, which allows you a better chance at matching things that I may say and thinks that the system has in its database that I'm not exactly the same. I could just yesterday. Yesterday I was an undergraduate student who in one of their internships, built one of the systems. And she basically explained to me all of the details. I'm arguing that the company gave her a questions, ask questions, answers, and she played the system so that it mimics that and it actually works. So this is an exactly where you, when you use this in a very specific context, like trying to solve a blending problem, we can do very well. But if you try to use these things in the wild, things can go really wrong because they really have no sense of what they're talking about. And the literature now because it's full of attempts that basic me pay, right? So you hear about chatbots that were used in the why not? What about a particular task? The exact some of the headlines is assisted by Microsoft. And because it just mimics data, it ended up really being racist. Sometimes people call in the system statistic and parrots, they just to compete based on data that they've seen. People try to say that this will stay Microsoft with something called Zoo after that for a few years and then it was shut down a couple of years ago. Again, it just didn't make sense when it was operating at this general environment because again, it has no idea what it's talking about, but it's not meaning behind these sentences. It's just doing statistical potential. You'll find a lot of stories like this online as well. So again, distinction is in-the-wild versus in a very specific objects for very specific tasks. And yes, they don't know what they're talking about, but they get it right a lot of the times and that would use a lot of bad. Before I leave this part. I want you to, if you have time, go look up something called GPP. Gpp is getting a lot of attention now it's one of these systems again based on machine learning and particular neural networks. We'll talk about this next. That can generate language. It looks like they're huge amount of text and it's almost like memorizes it. And some way you can go and give it like a leading sentence or two and it will continue the story for you. It's just mind boggling when you see basically how convincing it, it can be. And I want you to remember one number here, which is. The full burden of this has 175 billion parameters. We'll see what this means. It just ended. So check it out. If you can read about it, you can see what people do with it. You can even private action. Question the question that Nah, yes. Okay. I think that's my intuition says that before generating stories, sugary, that you can do translation in a, in a, in a, in a very good way. This is, this will be the first step, you know, due to generate, store a human to be the author. To translate, you just need to take one also only one language and translate well in say, another language. So I wonder if this story generation is up too much a pie in the sky. In other words, it, it, it's a, it's a, it's something that you strive for. Each file for the current research, which is, which reminds me of other questions in the past, which will very interesting. But too far and too far with asking questions to farm as will contribute much. And I wonder because I've, I've read, talks about language generation. And it looks to me, I don't know. Hi. This is, and then I'll tell you a quick story now, but I finished, we can have a discussion at the end. I'll tell you what they quickly. I was sitting at the dinner table with one of the top guys is one of these and they were bragging about this. Although compose when you're writing emails and how it will finish your sentences light. So this is, you can think of this as you look at this and say, okay, I hope you are and then doing well. And you can look at this and say, they were bragging about how much people adopt. The percentage of people that actually accept these competitions is just remarkably high. You can look at this and say, fantastic AI technology at it and say, This tells us about how prototypical our conversations about our composition Africa, it's easy to predict light. When you started, hope you, everybody would finish that. So we can talk about this later. The short story is, and I had a video on this. Maybe I'll mention it later. It will be this tells us more about not the technology, about the problems you're solving when you're able to use something as simple as this and press liquidity, 24 different languages that tells you something about the structure of language and its regularity more than anything else. And that's not what people look at today. But I think that's where basically everybody wants to know why are these things working? Well, look at the problems, not just at the technology. And maybe that will give you insights about what's going on. Alright, so I want to move on. I want to talk now about learning because that's where a lot of the things that are happening today and learning is a big subject. So I'm going to just like summarize few bullets, release and civic subject. Because when you're learning, what are you learning from? What are you learning? What is the purpose of learning? But there are three distinct things that, that now encapsulates a lot of what's happening in AI as far as learning is what? Supervised learning, unsupervised learning and reinforcement learning they were occupying basically a lot of the attention. Quickly. We're going to take a quick slide, a couple of slides about each one of them. Supervised learning is what is a lot of what's happening today and what's behind a lot of success tokens that you see and we see it's been a concrete example. Unsupervised learning is more difficult. And it's more like what humans do and what everybody aspires to do reinforcement learning. Let's get to it when we get to that slide, but let's talk about supervised. It's easy to explain this example. And in fact, this example was one of the first that drove a lot of progress on networks and supervised learning. This is where I'm going to give you images, digits, and I want you to recognize them. So I want a system that I give it an image like this one. And it says this is a five. I give it this guy here at the bottom coordinate axis, this is an I. And the way I'm going to do this is simply by taking images like this, which we call training data and have a human to come and look at them and label them. So a human would come and see this is a three. This is high, okay? So I have labeled data, that's what is supervised learning. You have labeled data input. And the human does the nape. Not. The most common approach for this study is what we're going to get a network. It looks like a circuit like this. It was initially one of us proposed more than 15 years ago to emulate neurons in the brain. You have these inputs, which in this case will be the pixels of the image. And the output here is saying, this is at one, this is a 0. Now, these boxes here I quote, neurons, each one is doing a simple computation. It's getting numbers on these wires. And each y, it has a number attached, it's called the parameter. And the idea is I want to learn these parameters because what each little thing here is doing is taking the signals that it's coming and multiplying them by the parameters on these wires and then outputting another number. So the behavior of this circuit is dependent on these parameters that you learn. Remember when we talked about GPT, a 175 billion parameters, that's basically the kind of scale. I want to produce that kind of effects. Now, the big thing is the following. It, what you do is you give me input, output, input, output, this is labeled data, and then you try to find the values of these parameters so that you start mimicking this template output. And that's when we have trained this thing. Neural networks have been around for at least 50 years. Over the last five to eight years. This is where they had the biggest splash. What happened? Initially, they were all looking like this. You have the input layer, maybe one or two, what people call hidden layers, and then the output. And the reason is we could only play these kind of things today. They look like this. We have many of these hidden layers before we get to the output. And so they are deeper. And that's where the term deep learning comes in. Because we're working with deeper neural network and we know how to train them. There's all kind of significant advances. I'll give you a point that if you want to read about what really happened that allowed us to trade these things in a better way today. And that's basically what's going on. This is underlies vast majority of what you see today, just American input-output. And we will look at it. One of the biggest areas where they had made an impact is in natural language and talk about and envision image analysis. So now you can go and look at images like this and see this is a cat and not only that, but you can put a box around the cat. You can have multiple objects. You can go and say, this is a dog, this is a cat, this is a dot. And doing this is only based on taking images. When humans went and put these boxes and set the unit outward, behavior, you have no idea what that is. You have no idea that the cat must have a head and it still does look like that or a dog has announced that look like that. None of that people try to do this long time ago, but that's not what's happening there. I'm just imitate the input-output behavior. And the remarkable thing is they basically doing better than anything that we've tried it before. But because they don't know any, maybe what's going on. You can easily format at. The literature now is full of examples when you take an image like this, by the way, every pixel is a set of numbers. So you can go and modify these numbers by introducing what we call noise. That when you portray the image again using these modified numbers, you and I look at it and say thanks. So this is a dog, this is a doc for you or not. But the neural network will go and say this is an ostrich, get completely confused and thrown away. Because again, it has no idea that their eyes and nose dives knowing something else. And this is called adversarial attacks. Look it up. It's everywhere today. People trying to see how can you build systems that are not easy to attack by fooling them and so on. So it's just a couple of words on the other two things. And then another Muslim parts idea, unsupervised learning. There is no notion of input, output. You are basically working with patterns. And maybe I'll give you a concrete example from what people call recommender systems. When you observe people, let's say purchasing hyphens or watching movies. And you start coming up with a model of face or interest and then you use it. It's a big deal. If you're not, we'll do this, then you can start popping ads to people. You can start supplementing product. The idea here is, let's say you have the stifle. You've got John and John rank this, this way around this, the Sweden when Frank, Sam and suddenly they all did the rankings. There is no input, output here, but it's just John and some behavior of John and Sam and Sydney. And then you can go and do unsupervised learning and you learn something, and then now you use reasoning. So Bob comes and Bob says, I rang this five by rank this one. And based on the learned model and reasoning, you can go say I'll be, I think Bob would rank list 3.51.7. So I'm not going to recommend this, but I'm going to comment this. All right? So there is no input up with is that easy to detect patterns? It's more typical. We'd like to do this. Labeling data is very difficult and consuming. You need a human to do that. In this case, there is no labeling process and so on. Now, reinforcement learning, which is getting a lot of attention today. Some of the stories you've heard about how ai is now playing games and beating humans. The short story is this. If you look at supervised learning, think of a little box. I give you input and I give you an output and I say mimic that input, output. Here. It's a similar story, but I don't have just one box. I have a cascaded boxes. So box one, the output goes to box to box to generate an output goes to box three. The difference is, I want to train these boxes, but I'm not going to tell you what is the input and output. One of them, I'm just going to give you the input of the first one and the output of the very last one. And again, this is like I'm making an action. I do an action. The game changes state, I go another action, and then I do another action. I cannot tell you how would each one of your actions are. I'm only going to tell you the sequence of actions, whether you won the game or not. And this is the feedback that I'm giving you, that one are the sport. Well, so it's basically this, this notion web when I have sequences of actions and the reward, or the label is basically delayed. There are some fantastic YouTube videos online about learning and reinforcement learning and how it works. For games and so on it and you can check out. So let me conclude with this thing. This is pretty important and for you as newcomers, and we've heard a lot about the need to know something. These are some of the headlines that you see in a day and that spike something like this. Every day to day. Ai can read minds. Ai detects deceptions in. Ai can tell whether you're male or female from the smile can predict public production, can recognize emotions, can then your personality trait from your eye movements. If these were headlines before deep learning and they would mean something else. The systems that are currently behind these up, pretty much all based on supervised learning. They have no idea what deception is, what the mind is, what emotion is, what personnel recuperate quickly on the last application. Eye movements, I think personally think what happened here is recorded eye movements and then asked people to fill a questionnaire like you see online, which you asked that question and then they take it personally, get back. So this is the labeled output. So I recorded eye movements and then I figured out your pre-select trade by filling out the questionnaire. And then I give to the box input-output eye movements person at the three eye movement personally, I asked this box to try to mimic that relationship. All right. So well at, but have no idea what a question about the grade is, just mimicking input, output. But we've seen some of the shortfalls of that. Eddie had been very beginning talk about people trying to come what mind these neural network approaches will be more traditional approaches today that's happening under something called new to symbolic AI. That's not an area where people are trying to combine these kind of things. I do work on this subject as well. The idea is, can I give you to get the best of the towards it's not easy for all kind of reasons. Some of them are just technical. Some of them have to do with the way science works. And that these two communities are somewhat disjoint that we can talk about the time at the end, whatever than I am. I want to talk about the kind of last subject here which has also been making use and that's okay, not planning, planning, I'm going to skip except to say that since u du now in an a, you can check the JPL job Propulsion Lab where they really do work on planning. You can take their webpages. There's a lot of interesting thing happening, so check it out. I'm going to go to the very last topic. Let's see how much I think that robotics. So this is something also that this publicly visible. The key thing here is to realize when you look at this, the textbook, you find that people categorize robots are too frequent equal to 0. And that is what people call manipulators. The kind of things you find like an assembly floors and factories. They're just trying to do something mechanical, very useful. They probably don't get any attention. There's not much in Greek there. They're everywhere. Okay. The other two types are mobile robots that are mostly going from one next to the other, whether it's through land, air, water, rovers like we've seen in the previous slide. And this is where like self-driving cars with n. Okay, so we're going to zoom in on that end. And the last thing is mobile robots that have manipulators and they're like mimicking humans. This is more likely start to figure the data. Or what you would see in movies, in Hollywood, movies about AI. Okay, that kind of things, that do everything. So just a word on each one of these and then rooms with Zoom. Okay, this is a picture of a robot in an assembly line. Okay. Fantastic stuff doesn't get attention to people who don't even depressed. What does AI? Because it's just like a mundane seeing useful. This is the last time where you're trying to have a role or that people imagined it in movies and people had in mind when they started with the thing that can walk and talk and and see and do all kinds of things. There is not much Week me, I'm out for these things in an agenda and upsetting. Honda was one of the companies that we're pursuing this called Asimo. And these are picture, you're going to find a lot of entertaining videos about that. But a couple of years ago they just basically could that project and they're not pursuing it anymore. So you don't see much of bad. We don't know how to do this like really, but the systems that can do all of these things and operate. And why I'm now we're going through the the the mobile stand here are a couple of history because it's very important because now you see self-driving cars. Do you talk about desolate roundabout way more than you have to know that 2004 was the first time people try to do that. Darpa is a major funding agency, et cetera, competition to try to have an autonomous vehicles go from one basic California to what makes them feel better. They had a $1 billion price for that. It was a lot of teams that try to speak only 50 qualified, none of them did. The forgiveness that any of them could go is 7.4 miles. This is like desert. This is empty land and this is about 15 years ago. And then what happened after that is the next year they up the award, $2 million, they shorten, edited. But then guess what, 24 robot. Fight and fight, actually finished. Let's make they grow under 32 miles in six hours. And this was the beginning of this whole grand about self-driving cars and to use after that in 2007. So this is all still emptied out. And 2007, which is not too far, It's when they did the competition and that was the first time that coursework live in an urban setting or item where they interacted with both manned and unmanned vehicles. This is like a major milestone that has a lot of material of this on the web. There are all kind of funny videos you can watch about the teams while they were practicing and preparing. I hope what if I check it out? Details. And of course now roll back then 15 years later, we have basically self-driving cars. Now. This is interesting because on the one hand, you do have systems that can drive autonomously for some extent. You have like way when I have a service where you can really call it as a taxi and cardboard come without the driver. And thank you. I have two students, PhD students who are now finished and work that way more. They invited me for way more light. I haven't done it yet. But there's a lot of surprises is controversial subject, right? So people predicted that we would go way further than what we did today. You would see headlines today. Basically show how the predictions about how far would have been seven black bars didn't go as much as people expect that. There's all kind of stories about that in the literature just a couple of weeks ago. You may want to check it. There was this interesting story about way more cars doing something very weird. San Francisco, there's just two weeks ago. So what happened here is, is pretty important. Let's talk about this quickly here. What worked, what didn't work? So we know how to drive things like airplanes were male on time, right? There's autopilots on airplanes and they make, they land autonomously, right on airport and so on. But it's a very structured environment. The sensing aspect of it is very simple. We know how to control that leg in order to control it. Something to go from one to the other. But when you're doing something right, because the environment is very different, it is unstructured. The biggest advances that happened is in sensing. These cars now can see, right? They, they can see the before. And this is due to the advances of being able to recognize things and so on, of course, somewhat control. The other thing you probably, maybe don't know is that these cars have extremely detailed maps. So your normal Google Maps now way more as part of Alphabet, but their maps, I've not Google Maps. They have their own maps which are significantly more deeply at Iraq building and every coordinate its own store. And then using it to do That's what's missing. And that is sitting behind all of these failures that you see is the lack of common sense. They don't have common sense. They don't know, they cannot reason. They don't understand the environment. If a guy sitting on one side of the street and started screaming and the other guy started screaming back. They are not able to think that there's a crisis and that is someone who's about fast, that they have no sense of that. Took to get to that level, you need to start reasoning and thinking and having knowledge and assistance. Do not do that. So if they see a normal situations but not appear in the training data at a baby who have issues brings back. That's a fantastic thing that you can do this now. But whether it's really missing is real intelligence, right? But it's again remarkable how far you can go with just mimicking and being a statistic, I'm better. Now, if you go to more controlled environments and I'll give you an example of this. I don't know if you've seen these. These are like little robots that you can have at home that would bleed. They would roam. I have one of these my wife loves that actually it's fantastic that these guys had been obsessing, emitted intelligence. You know how to avoid falling off stairs. They can navigate the house. You can even build a map of the house needs to be. And when they're done, they go back to that station and bug themselves to the chart for autonomous supporting this fall, they gotten their beds, other characters. Okay, this is a more controlled environment, even more specific task. And the technologies that would produce a lot of great value. So the thing that you need to be aware of is this notion of, are we doing in the wild or are we operating in a controlled by us? Are we trying to do general task or doing specific task? And that is a huge difference in terms of how successful these technologies end up being based on that adequately. Slides. Okay, so we've talked about needing to integrate symbolic and your approaches. And I mentioned you're a symbolic AI as something that people today to work on some other things that people are grappling with and they're getting a lot of potential fairness. When you do mimicking the data. The data is unpaired. Manually put you something that's upset. In fact, that is the cockpit immersive. That is, what is the problem? Is that the AI system that is the big unfair or is the data unfair? As simple as it sounds, It's not something, it's very bright, but making data can get you in trouble if the data is problematic. We talked about causality. This is getting a lot of attention today. I'm mentioning it again because do the arithmetic something nice article in the Wall Street Journal for a very public audience. And really in a very high level non-technical way. Explain it. The kind of trouble you can get in if you do not understand cause and effect and how you can really go completely white. So check it out, find that you may want to read this article. Another area that's getting a lot of attention to these explainability. Why did the system do something? If you build a system that mimics data, It's time to decide whether an applicant should be admitted to college or should be given a loan or not. And this is to say admit them, are going to admit them. Why? In fact, in some areas like credit, in the US, you are bound to give an explanation to the person. Why did you decline them? Why did you not give them alone? So explaining the behavior of these things is very important. It's an area that I've been doing a lot of work on, which is generating explanations of systems, including neural networks by the way. So this is something you see the pattern glaucoma. And so just to conclude a few, at the undergraduate level, we have actually quite a bit of horses that touches in the subjects, but the more general ones at least of course there's one on general AI which covers more what I talked about. Course on machine learning would just zoom in and machine learning, but we also have courses now, if you just wanted to vision or image analysis and install and you can fight that. So I wrote this article a couple of years ago. It appeared on the cover off the communications of the ACM, just like the largest topic, kitchen and computer science, which gives this high-level overview of the state of AI and it has a subtype. The title is human level intelligence, abilities and stuff like that is what just happened in AI and how it's me. Sometimes that so at least from one outlet, the ACM Digital Library, there was a require hands-on download. Some people are reading it, you may want to read it as well, so and see what's going on. Thank you. Thank you. Any questions? Raised your hand if you have a question? Normally has a question, let me ask you a question. I'm older than you, but you has been around also a long time. And before the league learning, everybody was talking about. And I, for me seeing promising, promising for so many decades and not delivering so loud. Deep learning delivered and deep learning, you thought of all the time-saving doesn't understand what it is doing, it doesn't understand what you're doing. So we for 50 years trying to do the understanding that did not succeed. Why do you think that now? We will succeed the reason out, and I would say perhaps what is missing is what's happened here. We're driving to understanding and somebody come, come along with new technology or the digital technology changes anything other than ignored nothing. And perhaps therefore the next step we don't, we will not succeed with understanding. We will succeed. Another new technology that will come in that perhaps will mimic their brain because this is not the deep learning is not what's happening in the brain. That's everybody, every nor, nor science will tell you this. So what gives you the confidence to continue in the same path of the past? So again, this is something that's exactly what this article gets to. First of all, this is a neural network is nothing new technology it has been around. And just like you say the other approaches that work, it was also labeled as it did work. And in this article, and this is now widely accepted that what happened with neural networks, it's the amount of data, the amount of compute power, and very importantly, applications. I talked, for example, about machine translation. If you win, when people said the older approaches didn't work, they had a completely different measure of success. All right, So what happened is that it's not just technology, is that we identify the old set of applications that you can do a reasonable job on, but it was still view it as success. So there are major issues that you did not have these applications. People maybe would have a different view on to what extent this kind of technology is successful or not. Now, it is not acknowledged. The, the, the, the limitations about neural networks is acknowledged widely, including people who are brilliant and networks where the disagreement. Is, is the solution just purely in doing neural networks and fixing them or doing other things. This is where they secrete, but there's no disagreement now about the limitations, about wanting to do something, excuse me. See, for example, Bengio, who was one of the main people and was awarded the Turing Award of the subject. Gibbs talks about this. It really gives you a very long list of issues that you hear them and you say, wait a minute, isn't this what symbolic AI supposed to do? But they still think that now. So this is where it might have been cycling, and by the way then it's not and they're not in competition. For example, in certain areas, explainable AI group for example, I don't care. How are you doing. Symbolic AI comes in at another LeBron, comes in for metal. Easy. If you have a box, it could be a neural network, that could be a Bayesian network classifier, could be a random forest classifier. I'm doing melodies and I think it's input, output behavior. I capture it symbolically and then start reasoning about it. So it's completely orthogonal, it's complementing. So you can build your MCS the way you want. But if you want to reason about it and see why you could do something, How could it do things differently? I invoke these other novel is knowing what did your networks. So this is like not competition, complementation. Write my report recently. This is what the theme is our reasoning about the behavior of AI systems. From the few survivors, this is like the TV or the pupil will not look, look at question two, courses or don't wish. Just a quick question. Yeah, There was a question in the chat saying, how does linguistic relate to NLP? Where linguistics deal with language, the other approaches, we will talk about grandmother and semantics of language. So that's where the intersection is. In fact, some of the people that were doing NLP you would be sitting and linguistics department traditionally, suddenly as much as Minimap network question in the chat. So you see, I think that it would be interesting, forget about the marriage. I didn't believe the marriage at the moment that you will maybe what they call now all deny in UAE or AI and prevent the phenomena of having a picture of a cat and some special noise and getting it to be an airplane or something like this. Because I think this is, this is the big problem of the deep network. In my mind, nobody get an a in my mind. Deep, deep, deep learning is, has sort of the Heisenberg heisenberg phenomena. In other words, you will not get rid of this problem, which no one net of, you know, doing special noise and moving one to the other. Because the success in vacuum in a, in a normal environment is that you do with coding. You put thinks far from each other. When you do the learning and you'll get all sorts of things you cannot really put and some things are very close and if you give it the right noise, it will go for one to two. Disease. This is unavoidable. And, and, and, and self-driving cars will do x events. We will not be able perhaps to explain, but you have to get the populace to agree that if they make these mistakes so readily compared to human being, that you get, you take this, you take the sprint. This is not agreeable. This is the big problem, in my opinion, is people think about software as the old software or not. If I understand. Yeah, I understand. So so I'll tell you what you're going along these lines. Every time I see one of the success stories. Again, traditionally person would say, wow AI, and I'm thinking, wow, we just learn something about this problem. I tell people. If you see that the same technology, the same thing is, is able to translate between almost every pair of languages without really needing to know much about each language. That is something intriguing about language. As much as it is in bringing about neural networks. Because it's telling us something about the structure of language. Once more when you're able to do completing sentences with people, compose an email so successfully and so easily. It's also paying you something about how we communicate today and outward got our communication. I think what neural networks access has told us, at least for me, is, is something about our world and how structured and how the patterns that govern some complex phenomena is that what now able to capture them? And again, I spoke about, in particular, I have a YouTube channel for people who may be interested. Automated reasoning at UCLA. I had a talk about mother-baby based model line approaches where I elaborate more on this. That many things that we thought we need to get it to capture you need to model. We do not need to. We can approximate them to a reasonable extent. Bikes if you're looking at that input-output. And that is in a sense, is not hard to believe. What we discovered is the size of these functions with a 175 billion parameters. I can pretty much captured most of the text that's out there to the point that I can start mimicking. Yet if you give me a paragraph, I can give you following paragraphs that makes a lot of sense. Told us something about the size of these functions that are needed to capture the structure in the text that we have generated so far. This is not something that people spend a lot of time on. And I think that's what needs to be studied. What this is telling us about the world, about its structure and how complex that structure rates. Okay? So we have to factor in between students and the people running the class is now 12 forward. I think it's time to finish. All right. Thank you, everyone. Thank you. And see you next Thursday or next Friday. All right. Well, you have a homework fall from last time about besides yeah. Yeah. So okay. Okay. Buh-bye. Bye. Thank you. And now check.